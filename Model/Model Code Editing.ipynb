{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": [
     0,
     6,
     11,
     17,
     22
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting inits.py\n"
     ]
    }
   ],
   "source": [
    "%%file inits.py\n",
    "# %load inits.py\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def uniform(shape, scale=0.05, name=None):\n",
    "    \"\"\"Uniform init.\"\"\"\n",
    "    initial = tf.random_uniform(shape, minval=-scale, maxval=scale, dtype=tf.float32)\n",
    "    return tf.Variable(initial, name=name)\n",
    "\n",
    "def glorot(shape, name=None):\n",
    "    \"\"\"Glorot & Bengio (AISTATS 2010) init.\"\"\"\n",
    "    init_range = np.sqrt(6.0/(shape[0]+shape[1]))\n",
    "    initial = tf.random_uniform(shape, minval=-init_range, maxval=init_range, dtype=tf.float32)\n",
    "    return tf.Variable(initial, name=name)\n",
    "\n",
    "def zeros(shape, name=None):\n",
    "    \"\"\"All zeros.\"\"\"\n",
    "    initial = tf.zeros(shape, dtype=tf.float32)\n",
    "    return tf.Variable(initial, name=name)\n",
    "\n",
    "def ones(shape, name=None):\n",
    "    \"\"\"All ones.\"\"\"\n",
    "    initial = tf.ones(shape, dtype=tf.float32)\n",
    "    return tf.Variable(initial, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [
     0,
     15,
     24,
     32,
     39,
     87,
     111,
     123,
     135,
     141,
     150
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting utils.py\n"
     ]
    }
   ],
   "source": [
    "%%file utils.py\n",
    "# %load utils.py\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import networkx as nx\n",
    "from scipy.sparse.linalg.eigen.arpack import eigsh\n",
    "import sys\n",
    "import scipy.sparse as sp\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "\n",
    "\n",
    "def test_inputs(features, support, labels):\n",
    "    if np.isnan(features).any(): raise ValueError(\"Features contains nan\")\n",
    "    if np.isnan(support).any(): raise ValueError(\"Support contains nan\")\n",
    "    if np.isnan(labels).any(): raise ValueError(\"Labels contains nan\")\n",
    "    if np.isinf(features).any(): raise ValueError(\"Features contains inf\")\n",
    "    if np.isinf(support).any(): raise ValueError(\"Support contains inf\")\n",
    "    if np.isinf(labels).any(): raise ValueError(\"Labels contains inf\")\n",
    "\n",
    "        \n",
    "def parse_index_file(filename):\n",
    "    \"\"\"Parse index file.\"\"\"\n",
    "    index = []\n",
    "    for line in open(filename):\n",
    "        index.append(int(line.strip()))\n",
    "    return index\n",
    "\n",
    "\n",
    "def sample_mask(idx, l):\n",
    "    \"\"\"Create mask.\"\"\"\n",
    "    mask = np.zeros(l)\n",
    "    mask[idx] = 1\n",
    "    return np.array(mask, dtype=np.bool)\n",
    "\n",
    "\n",
    "def load_data(dataset_str):\n",
    "    \"\"\"\n",
    "    Loads input data from gcn/data directory\n",
    "\n",
    "    ind.dataset_str.x => arr of the feature vectors of the training instances as numpy.ndarray object;\n",
    "    ind.dataset_str.y => arr of the one-hot labels of the labeled training instances as numpy.ndarray object (|label| = number of classes); \n",
    "    ind.dataset_str.graph => arr of adjacency matrices as numpy objects\n",
    "    ind.dataset_str.test.index => index file for test values. To ensure we properly do ONE split for all possible hyperparameters\n",
    "    it simply is in Data/ind.all.test.index. This is NOT regenerated\n",
    "\n",
    "    All objects above must be saved using python pickle module.\n",
    "\n",
    "    :param dataset_str: Dataset name\n",
    "    :return: All data input files loaded (as well the training/test data).\n",
    "    \"\"\"\n",
    "    cwd = os.getcwd()\n",
    "    os.chdir(\"..\")\n",
    "    names = ['x', 'y', 'graph', 'sequences', 'labelorder']\n",
    "    objects = []\n",
    "    for i in range(len(names)):\n",
    "        with open(\"Data/ind.{}.{}\".format(dataset_str, names[i]), 'rb') as f:\n",
    "            if sys.version_info > (3, 0):\n",
    "                objects.append(pkl.load(f, encoding='latin1'))\n",
    "            else:\n",
    "                objects.append(pkl.load(f))\n",
    "\n",
    "    features, y_arr, adj_ls, sequences, labelorder = tuple(objects)\n",
    "    os.chdir(cwd)\n",
    "    \n",
    "    # Split all datasets into testing, training, and validation. The split of this data is fixed for each dataset\n",
    "    # because the numpy seed is fixed, currently the breakdown is train: 60, validation: 10, test: 30\n",
    "    idx = [y_ind for y_ind in range(y_arr.shape[0])]\n",
    "    np.random.shuffle(idx)\n",
    "    cutoff_1 = int(6*len(idx)/10)\n",
    "    cutoff_2 = int(7*len(idx)/10)\n",
    "    idx_train = idx[:cutoff_1]\n",
    "    idx_val = idx[cutoff_1:cutoff_2]\n",
    "    idx_test = idx[cutoff_2:]\n",
    "    idx_train, idx_val, idx_test = np.sort(idx_train), np.sort(idx_val), np.sort(idx_test)\n",
    "    \n",
    "    # make logical indices (they are the size BATCH)\n",
    "    train_mask = sample_mask(idx_train, y_arr.shape[0])\n",
    "    val_mask = sample_mask(idx_val, y_arr.shape[0])\n",
    "    test_mask = sample_mask(idx_test, y_arr.shape[0])\n",
    "\n",
    "    return adj_ls, features, y_arr, sequences, labelorder, train_mask, val_mask, test_mask\n",
    "\n",
    "\n",
    "def parse_many_datasets(datasets):\n",
    "    \"\"\"This method deals with many datasets being provided. The datasets MUST have the cardinality of node set.\"\"\"\n",
    "    datasets = datasets.strip()\n",
    "    if datasets[0] != \"[\" and datasets[-1] != \"]\":\n",
    "        return load_data(datasets)\n",
    "    datasets = datasets.strip(\"[]\")\n",
    "    datasets = datasets.replace(\" \", \"\")\n",
    "    datasets = datasets.split(\",\")\n",
    "    \n",
    "    # initialize with initial or first dataset, then simply concatenate each new dataset onto existing structure\n",
    "    adj_ls, features, y_arr, sequences, labelorder, train_mask, val_mask, test_mask = load_data(datasets[0])\n",
    "    for dataset in datasets[1:]:\n",
    "        if dataset != \"\":\n",
    "            adj_ls_curr, features_curr, y_arr_curr, sequences_curr, _, train_curr, val_curr, test_curr = load_data(dataset)\n",
    "            adj_ls = np.concatenate((adj_ls, adj_ls_curr), axis = 0)\n",
    "            features = np.concatenate((features, features_curr), axis = 0)\n",
    "            y_arr = np.concatenate((y_arr, y_arr_curr), axis = 0)\n",
    "            train_mask = np.concatenate((train_mask, train_curr), axis = 0)\n",
    "            val_mask = np.concatenate((val_mask, val_curr), axis = 0)\n",
    "            test_mask = np.concatenate((test_mask, test_curr), axis = 0)\n",
    "            sequences = sequences + sequences_curr\n",
    "    return adj_ls, features, y_arr, sequences, labelorder, train_mask, val_mask, test_mask\n",
    "        \n",
    "\n",
    "def preprocess_features(features):\n",
    "    \"\"\"Row-normalize feature matrix and convert to tuple representation\"\"\"\n",
    "    for i in range(features.shape[0]):\n",
    "        feature_arr = features[i,:,:]\n",
    "        rowsum = np.array(feature_arr.sum(1))\n",
    "        r_inv = np.power(rowsum, -1).flatten()\n",
    "        r_inv[np.isinf(r_inv)] = 0.\n",
    "        r_mat_inv = np.diag(r_inv)\n",
    "        features[i,:,:] = r_mat_inv.dot(feature_arr)\n",
    "    return features\n",
    "\n",
    "\n",
    "def normalize_adj(adj):\n",
    "    \"\"\"Symmetrically normalize adjacency matrix.\"\"\"\n",
    "    # added a shift to be non negative\n",
    "    adj += np.amax(adj)\n",
    "    # normalize\n",
    "    rowsum = adj.sum(1)\n",
    "    d_inv_sqrt = np.power(rowsum, -0.5).flatten()\n",
    "    d_inv_sqrt[np.isinf(d_inv_sqrt)] = 0.\n",
    "    d_mat_inv_sqrt = np.diag(d_inv_sqrt)\n",
    "    return adj.dot(d_mat_inv_sqrt).transpose().dot(d_mat_inv_sqrt)\n",
    "\n",
    "\n",
    "def preprocess_adj(adj):\n",
    "    \"\"\"Preprocessing of adjacency matrix for simple GCN model and conversion to tuple representation.\"\"\"\n",
    "    adj_normalized = normalize_adj(adj + np.identity(adj.shape[0]))\n",
    "    return adj_normalized\n",
    "\n",
    "\n",
    "def construct_feed_dict(features, support, labels, placeholders):\n",
    "    \"\"\"Construct feed dictionary.\"\"\"\n",
    "    feed_dict = dict()\n",
    "    feed_dict.update({placeholders['labels']: labels})\n",
    "    feed_dict.update({placeholders['features']: features})\n",
    "    feed_dict.update({placeholders['support']: support})\n",
    "    return feed_dict\n",
    "\n",
    "\n",
    "def chebyshev_polynomials(adj, k):\n",
    "    \"\"\"Calculate Chebyshev polynomials up to order k. Return a list of sparse matrices (tuple representation).\"\"\"\n",
    "\n",
    "    adj_normalized = normalize_adj(adj)\n",
    "    laplacian = np.identity(adj.shape[0]) - adj_normalized\n",
    "    try:\n",
    "        largest_eigval, _ = eigsh(laplacian, 1, which='LM') # should still work\n",
    "    except:\n",
    "        largest_eigval, _ = eigsh(laplacian, 1, which='LM') # should still work, some wierd bug\n",
    "        \n",
    "    scaled_laplacian = (2. / largest_eigval[0]) * laplacian - np.identity(adj.shape[0])\n",
    "\n",
    "    t_k = list()\n",
    "    t_k.append(np.identity(adj.shape[0]))\n",
    "    t_k.append(scaled_laplacian)\n",
    "\n",
    "    def chebyshev_recurrence(t_k_minus_one, t_k_minus_two, scaled_lap):\n",
    "        s_lap = sp.csr_matrix(scaled_lap, copy=True)\n",
    "        return 2 * s_lap.dot(t_k_minus_one) - t_k_minus_two\n",
    "\n",
    "    for i in range(2, k+1):\n",
    "        t_k.append(chebyshev_recurrence(t_k[-1], t_k[-2], scaled_laplacian))\n",
    "\n",
    "    return t_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [
     0,
     12,
     21,
     29,
     73,
     86,
     125,
     127,
     143,
     196,
     200,
     214
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting layers.py\n"
     ]
    }
   ],
   "source": [
    "%%file layers.py\n",
    "# %load layers.py\n",
    "from inits import *\n",
    "import tensorflow as tf\n",
    "\n",
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "# global unique layer ID dictionary for layer name assignment\n",
    "_LAYER_UIDS = {}\n",
    "\n",
    "\n",
    "def get_layer_uid(layer_name=''):\n",
    "    \"\"\"Helper function, assigns unique layer IDs.\"\"\"\n",
    "    if layer_name not in _LAYER_UIDS:\n",
    "        _LAYER_UIDS[layer_name] = 1\n",
    "        return 1\n",
    "    else:\n",
    "        _LAYER_UIDS[layer_name] += 1\n",
    "        return _LAYER_UIDS[layer_name]\n",
    "\n",
    "def dot(x, y, sparse=False):\n",
    "    \"\"\"Wrapper for tf.matmul (sparse vs dense).\"\"\"\n",
    "    if sparse:\n",
    "        res = tf.sparse_tensor_dense_matmul(x, y)\n",
    "    else:\n",
    "        res = tf.matmul(x, y)\n",
    "    return res    \n",
    "    \n",
    "class Layer(object):\n",
    "    \"\"\"Base layer class. Defines basic API for all layer objects.\n",
    "    Implementation inspired by keras (http://keras.io).\n",
    "\n",
    "    # Properties\n",
    "        name: String, defines the variable scope of the layer.\n",
    "        logging: Boolean, switches Tensorflow histogram logging on/off\n",
    "\n",
    "    # Methods\n",
    "        _call(inputs): Defines computation graph of layer\n",
    "            (i.e. takes input, returns output)\n",
    "        __call__(inputs): Wrapper for _call()\n",
    "        _log_vars(): Log all variables\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        allowed_kwargs = {'name', 'logging'}\n",
    "        for kwarg in kwargs.keys():\n",
    "            assert kwarg in allowed_kwargs, 'Invalid keyword argument: ' + kwarg\n",
    "        name = kwargs.get('name')\n",
    "        if not name:\n",
    "            layer = self.__class__.__name__.lower()\n",
    "            name = layer + '_' + str(get_layer_uid(layer))\n",
    "        self.name = name\n",
    "        self.vars = {}\n",
    "        logging = kwargs.get('logging', False)\n",
    "        self.logging = logging\n",
    "\n",
    "    def _call(self, inputs):\n",
    "        return inputs\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        with tf.name_scope(self.name):\n",
    "            if self.logging:\n",
    "                tf.summary.histogram(self.name + '/inputs', inputs)\n",
    "            outputs = self._call(inputs)\n",
    "            if self.logging:\n",
    "                tf.summary.histogram(self.name + '/outputs', outputs)\n",
    "            return outputs\n",
    "\n",
    "    def _log_vars(self):\n",
    "        for var in self.vars:\n",
    "            tf.summary.histogram(self.name + '/vars/' + var, self.vars[var])\n",
    "\n",
    "class Flatten(Layer):\n",
    "    \"\"\"Flattens a tensor layer.\"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Flatten, self).__init__(**kwargs)\n",
    "\n",
    "    def _call(self, inputs):\n",
    "        x = inputs\n",
    "        # flatten the tensor to one layer\n",
    "        shape = x.get_shape().as_list()               # a list: [None,...]\n",
    "        dim = np.prod(shape[1:])                   # dim = prod(...)\n",
    "        x_flattened = tf.reshape(x, [-1, dim])        # -1 means \"all\"\n",
    "        return x_flattened\n",
    "    \n",
    "class Dense(Layer):\n",
    "    \"\"\"Dense layer.\"\"\"\n",
    "    def __init__(self, input_dim, output_dim, placeholders, dropout=0.,\n",
    "                 act=tf.nn.relu, bias=False, featureless=False, **kwargs):\n",
    "        super(Dense, self).__init__(**kwargs)\n",
    "\n",
    "        if dropout:\n",
    "            self.dropout = placeholders['dropout']\n",
    "        else:\n",
    "            self.dropout = 0.\n",
    "\n",
    "        self.act = act\n",
    "        self.featureless = featureless\n",
    "        self.bias = bias\n",
    "\n",
    "        with tf.variable_scope(self.name + '_vars'):\n",
    "            self.vars['weights'] = glorot([input_dim, output_dim],\n",
    "                                          name='weights')\n",
    "            if self.bias:\n",
    "                self.vars['bias'] = zeros([output_dim], name='bias')\n",
    "\n",
    "        if self.logging:\n",
    "            self._log_vars()\n",
    "\n",
    "    def _call(self, inputs):\n",
    "        x = inputs\n",
    "\n",
    "        # dropout\n",
    "        x = tf.nn.dropout(x, 1-self.dropout)\n",
    "        \n",
    "        # transform\n",
    "        output = x @ self.vars['weights']\n",
    "        \n",
    "        # bias\n",
    "        if self.bias:\n",
    "            output += self.vars['bias']\n",
    "    \n",
    "        return self.act(output) # BatchOutput\n",
    "\n",
    "class GraphConvolution(Layer):\n",
    "    \"\"\"Graph convolution layer.\"\"\"\n",
    "    def __init__(self, input_dim, output_dim, placeholders, dropout=0.,\n",
    "                 act=tf.nn.relu, bias=False,\n",
    "                **kwargs):\n",
    "        super(GraphConvolution, self).__init__(**kwargs)\n",
    "\n",
    "        if dropout:\n",
    "            self.dropout = placeholders['dropout']\n",
    "        else:\n",
    "            self.dropout = 0.\n",
    "\n",
    "        self.act = act\n",
    "        self.support = placeholders['support']\n",
    "        self.bias = bias\n",
    "        self.num_nodes = self.support.get_shape().as_list()[2]\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        with tf.variable_scope(self.name + '_vars'):\n",
    "            # make all weight matrices for supports in convolution\n",
    "            for i in range(self.support.get_shape().as_list()[1]):# support: ?xSupportsxNxNxM\n",
    "                for j in range(self.support.get_shape().as_list()[4]):\n",
    "                    tensor_name = 'weights_support_' + str(i) + '_M_' + str(j)\n",
    "                    self.vars[tensor_name] = glorot([input_dim, output_dim], name=tensor_name)\n",
    "            # make vector to do weighted sum of all convolved features (w in SUM(wi*(NxF')) for w in M)\n",
    "            self.vars[\"Features Combination\"] = tf.Variable(tf.random_uniform([self.support.get_shape().as_list()[4]]))\n",
    "            # make bias matrice\n",
    "            if self.bias:\n",
    "                self.vars['bias'] = zeros([output_dim], name='bias')\n",
    "        if self.logging:\n",
    "            self._log_vars()\n",
    "\n",
    "    def _call(self, inputs):\n",
    "        x = inputs\n",
    "        \n",
    "        # dropout\n",
    "        x = tf.nn.dropout(x, 1-self.dropout)\n",
    "        \n",
    "        # convolve\n",
    "        convolved_features = []\n",
    "        for j in range(self.support.get_shape().as_list()[4]):\n",
    "            temp = []\n",
    "            for i in range(self.support.get_shape().as_list()[1]):\n",
    "                tensor_name = 'weights_support_' + str(i) + '_M_' + str(j)\n",
    "                # BatchNF * FF' weight tensor (num_nodes, |Features'|)\n",
    "                (N, F) = x.get_shape().as_list()[1:]\n",
    "                embed = tf.reshape(x, [-1, F])\n",
    "                pre_sup =  tf.reshape(tf.reshape(x, [-1, F]) @ self.vars[tensor_name], [-1, N, self.output_dim])\n",
    "                (batch, _, F_new) = pre_sup.get_shape().as_list()\n",
    "\n",
    "                # BatchNN * BatchNF' => BatchNF'\n",
    "                support = tf.slice(self.support, [0,i,0,0,j], [-1,1,-1,-1,1]) # get Batch1NN1\n",
    "                support = tf.reshape(support, [-1,N,N]) # reshape to BatchNN\n",
    "                support = support @ pre_sup # now BatchNF'\n",
    "                temp.append(support)\n",
    "            # adds together list of BatchNF' into one BatchNF' for a single original adjacency matrix\n",
    "            convolved_F = tf.add_n(temp)\n",
    "            convolved_features.append(convolved_F)\n",
    "        # stack list into one tensor of shape BatchNF'M\n",
    "        convolved_features = tf.stack(convolved_features, axis = 3)\n",
    "        # do weighted multiplication\n",
    "        convolved_features = tf.multiply(convolved_features, self.vars[\"Features Combination\"])\n",
    "        # sum together to remove 4th dimension\n",
    "        output = tf.reduce_sum(convolved_features, axis = 3)\n",
    "        \n",
    "        # bias\n",
    "        if self.bias:\n",
    "            output += self.vars['bias'] # Broadcasting spreads bias across Batch and Node dimensions\n",
    "\n",
    "        return self.act(output)\n",
    "\n",
    "class SelfAttention(Layer):\n",
    "    \"\"\"Self attention layer, input is in ?xNxhidden, output is in ?x(Bias*Hidden). Hidden should correspond \n",
    "    to the number of features nodes have.\"\"\"\n",
    "    \n",
    "    def __init__(self, attention_dim, bias_dim, hidden_units, placeholders, dropout=0., **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        if dropout:\n",
    "            self.dropout = placeholders['dropout']\n",
    "        else:\n",
    "            self.dropout = 0.\n",
    "        \n",
    "        self.hidden_units = hidden_units\n",
    "        self.A = None\n",
    "        with tf.variable_scope(self.name + '_vars'):\n",
    "            self.vars['Ws'] = glorot([attention_dim, self.hidden_units])#tf.Variable(tf.random_uniform([attention_dim, self.hidden_units])) # AttentionxHidden\n",
    "            self.vars['W2'] = glorot([bias_dim, attention_dim])#tf.Variable(tf.random_uniform([bias_dim, attention_dim])) # BiasxAttention\n",
    "\n",
    "    def _call(self, inputs):\n",
    "        # dropout\n",
    "        inputs = tf.nn.dropout(inputs, 1-self.dropout)\n",
    "        inputsT = tf.transpose(inputs, perm = [0, 2, 1]) # transpose the inner matrices which is our intention\n",
    "        \n",
    "        # AttentionxHidden * ?xHiddenxN => ?xAttentionxN\n",
    "        aux = tf.einsum('ah,bhn->ban', self.vars['Ws'], inputsT)\n",
    "        aux = tf.tanh(aux)\n",
    "        \n",
    "        # BiasxAttention * ?xAttentionxN => ?xBiasxN\n",
    "        self.A = tf.einsum('ba,uan->ubn',self.vars['W2'], aux)\n",
    "        self.A = tf.nn.softmax(self.A)\n",
    "        \n",
    "        # ?xBiasxN * ?xNxHidden => ?xBiasxHidden\n",
    "        out = self.A @ inputs\n",
    "        \n",
    "        # ?xBiasxHidden => ?x(Bias*Hidden)\n",
    "        out = tf.reshape(out, [ -1, out.get_shape().as_list()[1] * out.get_shape().as_list()[2]])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "code_folding": [
     0,
     8,
     100,
     190
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting models.py\n"
     ]
    }
   ],
   "source": [
    "%%file models.py\n",
    "# %load models.py\n",
    "from layers import *\n",
    "from metrics import *\n",
    "\n",
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "class Model(object):\n",
    "    def __init__(self, **kwargs):\n",
    "        allowed_kwargs = {'name', 'logging'}\n",
    "        for kwarg in kwargs.keys():\n",
    "            assert kwarg in allowed_kwargs, 'Invalid keyword argument: ' + kwarg\n",
    "        name = kwargs.get('name')\n",
    "        if not name:\n",
    "            name = self.__class__.__name__.lower()\n",
    "        self.name = name\n",
    "\n",
    "        logging = kwargs.get('logging', False)\n",
    "        self.logging = logging\n",
    "\n",
    "        self.vars = {}\n",
    "        self.placeholders = {}\n",
    "\n",
    "        self.layers = []\n",
    "        self.activations = []\n",
    "        \n",
    "        self.inputs = None\n",
    "        self.outputs = None\n",
    "        self.logits = None\n",
    "        self.predictions = None\n",
    "        self.attentions = None\n",
    "        \n",
    "        self.loss = 0\n",
    "        self.accuracy = 0\n",
    "        self.f1_score = 0\n",
    "        self.optimizer = None\n",
    "        self.opt_op = None\n",
    "\n",
    "    def _build(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def build(self):\n",
    "        \"\"\" Wrapper for _build() \"\"\"\n",
    "        with tf.variable_scope(self.name):\n",
    "            self._build()\n",
    "\n",
    "        # Build sequential layer model\n",
    "        self.activations.append(self.inputs)\n",
    "        for layer in self.layers:\n",
    "            hidden = layer(self.activations[-1])\n",
    "            self.activations.append(hidden)\n",
    "        self.outputs = self.activations[-1]\n",
    "\n",
    "        # Store model variables for easy access\n",
    "        variables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=self.name)\n",
    "        self.vars = {var.name: var for var in variables}\n",
    "\n",
    "        # Build metrics\n",
    "        self._loss()\n",
    "        self._accuracy()\n",
    "        self.opt_op = self.optimizer.minimize(self.loss)\n",
    "\n",
    "    def predict(self):\n",
    "        pass\n",
    "\n",
    "    def _loss(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def _accuracy(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def save(self, sess=None):\n",
    "        if not sess:\n",
    "            raise AttributeError(\"TensorFlow session not provided.\")\n",
    "        saver = tf.train.Saver(self.vars)\n",
    "        save_path = saver.save(sess, \"tmp/%s.ckpt\" % self.name)\n",
    "        print(\"Model saved in file: %s\" % save_path)\n",
    "\n",
    "    def load(self, sess=None):\n",
    "        if not sess:\n",
    "            raise AttributeError(\"TensorFlow session not provided.\")\n",
    "        saver = tf.train.Saver(self.vars)\n",
    "        save_path = \"tmp/%s.ckpt\" % self.name\n",
    "        saver.restore(sess, save_path)\n",
    "        print(\"Model restored from file: %s\" % save_path)\n",
    "\n",
    "\n",
    "class GCN(Model):\n",
    "    def __init__(self, placeholders, input_dim, **kwargs):\n",
    "        super(GCN, self).__init__(**kwargs)\n",
    "        self.inputs = placeholders['features']\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = placeholders['labels'].get_shape().as_list()[1]\n",
    "        self.placeholders = placeholders\n",
    "        self.number_nodes = placeholders['features'].get_shape().as_list()[1]\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate=FLAGS.learning_rate)\n",
    "        self.attention_layer = None\n",
    "        self.build()\n",
    "\n",
    "    def _loss(self):\n",
    "        # Weight decay loss\n",
    "        for var in self.layers[0].vars.values():\n",
    "            self.loss += FLAGS.weight_decay * tf.nn.l2_loss(var)\n",
    "        \n",
    "        if FLAGS.balanced_training == \"True\":\n",
    "            labels = self.placeholders['labels']\n",
    "            logits = self.outputs\n",
    "            # Get relative frequency of each class\n",
    "            class_counts = tf.reduce_sum(labels, 0)\n",
    "            class_frequencies = class_counts / tf.reduce_sum(class_counts)\n",
    "            # Cross entropy error\n",
    "            entropies = tf.nn.softmax_cross_entropy_with_logits_v2(logits = logits, labels = labels, dim = -1)\n",
    "            # Scale by 1/frequency\n",
    "            scalers = labels / class_frequencies\n",
    "            scalers = tf.reduce_sum(scalers, 1)\n",
    "            entropies_scaled = scalers * entropies\n",
    "            self.loss += tf.reduce_mean(entropies_scaled)\n",
    "        else:\n",
    "            # Cross entropy error\n",
    "            labels = self.placeholders['labels']\n",
    "            logits = self.outputs\n",
    "            entropies = tf.nn.softmax_cross_entropy_with_logits_v2(logits = logits, labels = labels, dim = -1)\n",
    "            loss = tf.reduce_mean(entropies)\n",
    "            self.loss += loss\n",
    "\n",
    "    def _accuracy(self):\n",
    "        labels = self.placeholders['labels']\n",
    "        logits = self.outputs\n",
    "        self.logits = logits\n",
    "        self.attentions = self.attention_layer.A\n",
    "        labels=tf.argmax(labels, 1) # labels\n",
    "        predictions=tf.argmax(logits, 1) # prediction as one hot\n",
    "        self.predictions = predictions\n",
    "        \n",
    "        # Define the metric and update operations, f1 score is also calculated\n",
    "        tf_metric, tf_metric_update = tf.metrics.accuracy(predictions = predictions, labels = labels, name = \"accuracy\")\n",
    "        self.accuracy = tf_metric_update\n",
    "        \n",
    "        # Isolate the variables stored behind the scenes by the metric operation\n",
    "        running_vars = tf.get_collection(tf.GraphKeys.LOCAL_VARIABLES, scope=\"accuracy\")\n",
    "        \n",
    "        # Define initializer to initialize/reset running variables\n",
    "        self.running_vars_initializer = tf.variables_initializer(var_list=running_vars)\n",
    "\n",
    "    def _build(self):\n",
    "        # Parse through the graph convolutional layer specifications and the hidden layers\n",
    "        def parse_array(string):\n",
    "            sl = list(string)\n",
    "            if sl[0] != \"[\" and sl[-1] == \"]\":\n",
    "                raise ValueError(\"Invalid dimensions input\")\n",
    "            string = string.strip(\"[]\")\n",
    "            string = string.replace(\" \", \"\")\n",
    "            num_ls = string.split(\",\")\n",
    "            return [int(x) for x in num_ls if x != \"\"]\n",
    "        graph_convolution_dimensions = parse_array(FLAGS.graph_conv_dimensions)\n",
    "        fully_connected_dimensions = parse_array(FLAGS.connected_dimensions)\n",
    "        \n",
    "        # Graph Convolutional Layers\n",
    "        prior_dimension = self.input_dim\n",
    "        for gcdim in graph_convolution_dimensions:\n",
    "            self.layers.append(GraphConvolution(input_dim=prior_dimension,\n",
    "                                                output_dim=gcdim,\n",
    "                                                placeholders=self.placeholders,\n",
    "                                                act=tf.nn.relu,\n",
    "                                                dropout=True,\n",
    "                                                logging=self.logging))\n",
    "            prior_dimension = gcdim\n",
    "        \n",
    "        # Self Attention\n",
    "        self.layers.append(SelfAttention(attention_dim=FLAGS.attention_dim,\n",
    "                                         bias_dim=FLAGS.attention_bias, \n",
    "                                         hidden_units=prior_dimension,\n",
    "                                         placeholders=self.placeholders,\n",
    "                                         dropout=True,\n",
    "                                         logging=self.logging))\n",
    "        self.attention_layer = self.layers[-1]\n",
    "        \n",
    "        # Fully Connected Layers\n",
    "        fully_connected_dimensions.append(self.output_dim)\n",
    "        prior_dimension = prior_dimension * FLAGS.attention_bias\n",
    "        for fcdim in fully_connected_dimensions:\n",
    "            self.layers.append(Dense(input_dim=prior_dimension,\n",
    "                                     output_dim=fcdim,\n",
    "                                     act=tf.nn.relu,\n",
    "                                     placeholders=self.placeholders,\n",
    "                                     dropout=True,\n",
    "                                     logging=self.logging))\n",
    "            prior_dimension = fcdim\n",
    "        \n",
    "    def predict(self):\n",
    "        logits = self.outputs\n",
    "        return tf.nn.softmax(logits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": [
     41,
     64,
     69,
     72,
     75,
     89,
     105,
     107,
     109,
     147,
     185,
     191,
     266,
     286,
     299
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting train.py\n"
     ]
    }
   ],
   "source": [
    "%%file train.py\n",
    "# %load train.py\n",
    "\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from utils import *\n",
    "from models import GCN\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "\n",
    "# Set random seed\n",
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)\n",
    "\n",
    "# Settings\n",
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "flags.DEFINE_string('dataset', 'wholeset', 'Dataset string.')\n",
    "flags.DEFINE_string('model', 'gcn', 'Model string.')\n",
    "flags.DEFINE_float('learning_rate', 0.01, 'Initial learning rate.')\n",
    "flags.DEFINE_integer('epochs', 200, 'Number of epochs to train.')\n",
    "flags.DEFINE_string('graph_conv_dimensions', '[20,20]', 'Number of units in each graph convolution layer.')\n",
    "flags.DEFINE_string('connected_dimensions','[]', 'Number of units in each FC layer.')\n",
    "flags.DEFINE_integer('attention_bias', 2, 'Attention Bias.')\n",
    "flags.DEFINE_integer('attention_dim', 5, 'Attention Dimension.')\n",
    "flags.DEFINE_float('dropout', 0.5, 'Dropout rate (1 - keep probability).')\n",
    "flags.DEFINE_float('weight_decay', 5e-4, 'Weight for L2 loss on embedding matrix.')\n",
    "flags.DEFINE_integer('early_stopping', 10, 'Tolerance for early stopping (# of epochs).')\n",
    "flags.DEFINE_integer('max_degree', 3, 'Maximum Chebyshev polynomial degree.')\n",
    "flags.DEFINE_string('save_validation', \"False\", \"If you should save validation accuracy\")\n",
    "flags.DEFINE_string('save_test', \"False\", \"If this is a optimized run! Use all data and save outputs\")\n",
    "flags.DEFINE_string('test_dataset', 'testset', \"If we are testing with a unique test_set\")\n",
    "flags.DEFINE_string('balanced_training', 'False', \"use a weighted classwise loss to prevent favoring larger class\")\n",
    "\n",
    "# Load data\n",
    "adj_ls, features, y_arr, sequences, labelorder, train_mask, val_mask, test_mask = parse_many_datasets(FLAGS.dataset)\n",
    "\n",
    "# Check for independent test_dataset\n",
    "if FLAGS.test_dataset != \"testset\":\n",
    "    adj_ls_test, features_test, y_arr_test, sequences_test, _, _, _, test_mask = parse_many_datasets(FLAGS.test_dataset)\n",
    "    adj_ls = np.concatenate((adj_ls, adj_ls_test), axis = 0)\n",
    "    features = np.concatenate((features, features_test), axis = 0)\n",
    "    y_arr = np.concatenate((y_arr, y_arr_test), axis = 0)\n",
    "    sequences = sequences + sequences_test\n",
    "    # make all the indices true and false, then concatenate and invert for test and train\n",
    "    test_mask[0:len(test_mask)] = True\n",
    "    train_mask[0:len(train_mask)] = False\n",
    "    # test is now indexes of testset\n",
    "    test_mask = np.concatenate((train_mask, test_mask))\n",
    "    # make train test split\n",
    "    train_mask = np.array([not xi for xi in test_mask], dtype = np.bool)\n",
    "    idx = [i for i in range(sum(train_mask))]\n",
    "    np.random.shuffle(idx)\n",
    "    cutoff = int(6*len(idx)/7)\n",
    "    val_ind = idx[cutoff:]\n",
    "    train_ind = idx[:cutoff]\n",
    "    val_mask = np.array([xi in val_ind for xi in range(train_mask.shape[0])], dtype = np.bool)\n",
    "    train_mask = np.array([xi in train_ind for xi in range(train_mask.shape[0])], dtype = np.bool)\n",
    "\n",
    "# Save Name Defined by Model Params\n",
    "model_desc = \"lr_{7}_epoch_{8}_stop_{9}_gc_{0}_do_{1}_ad_{2}_ab_{3}_fc_{4}_m_{5}_deg_{6}\"\n",
    "model_desc = model_desc.format(FLAGS.graph_conv_dimensions, FLAGS.dropout, FLAGS.attention_dim,\n",
    "                              FLAGS.attention_bias, FLAGS.connected_dimensions, FLAGS.model, FLAGS.max_degree,\n",
    "                              FLAGS.learning_rate, FLAGS.epochs, FLAGS.early_stopping)\n",
    "\n",
    "# Determine Number of Supports and Assign Model Function\n",
    "if FLAGS.model == 'gcn':\n",
    "    num_supports = 1\n",
    "    model_func = GCN\n",
    "elif FLAGS.model == 'gcn_cheby':\n",
    "    num_supports = 1 + FLAGS.max_degree\n",
    "    model_func = GCN\n",
    "else:\n",
    "    raise ValueError('Invalid argument for model: ' + str(FLAGS.model))\n",
    "\n",
    "# Validating\n",
    "save_validation = FLAGS.save_validation\n",
    "if save_validation == \"True\": save_validation = True\n",
    "else: save_validation = False\n",
    "\n",
    "# Testing\n",
    "save_test = FLAGS.save_test\n",
    "if save_test == \"True\": save_test = True\n",
    "else: save_test = False\n",
    "\n",
    "# Make Dataframes\n",
    "if save_test:\n",
    "    epoch_df = pd.DataFrame(np.zeros(shape = (FLAGS.epochs, 5)))\n",
    "    labels_df = pd.DataFrame(np.zeros(shape = (sum(test_mask), 5)))\n",
    "\n",
    "# Print Basic Information\n",
    "print(f\"Graph: {FLAGS.dataset}, {FLAGS.test_dataset}\\nModel {model_desc}\")\n",
    "\n",
    "# Size of Different Sets\n",
    "print(\"|Training| {}, |Validation| {}, |Testing| {}\".format(np.sum(train_mask), np.sum(val_mask), np.sum(test_mask)))\n",
    "\n",
    "# Initial time\n",
    "ttot = time.time()\n",
    "\n",
    "# Preload support tensor so that it isn't needlessly calculated many times\n",
    "batch,_,N,M = adj_ls.shape\n",
    "support_tensor = np.zeros(shape=(batch,num_supports,N,N,M)) # of shape (Batch,Num_Supports,Num_Nodes,Num_Nodes,Num_Edge)\n",
    "if FLAGS.model == \"gcn_cheby\":\n",
    "    print(\"Calculating Chebyshev polynomials up to order {}...\".format(FLAGS.max_degree))\n",
    "else:\n",
    "    print(\"Preprocessing adjacency lists\")\n",
    "for b in range(batch):\n",
    "    adj = adj_ls[b]\n",
    "    for m in range(M):\n",
    "        adj = adj_ls[b][:,:,m] # first adjacency list\n",
    "        if FLAGS.model == 'gcn':\n",
    "            support = [preprocess_adj(adj)]\n",
    "        elif FLAGS.model == 'gcn_cheby':\n",
    "            support = chebyshev_polynomials(adj, FLAGS.max_degree)\n",
    "        # add NxN matrices along the num_supports dimension\n",
    "        sup = np.stack(support, axis=0)\n",
    "        # add num_supportsxNxN to support tensor\n",
    "        support_tensor[b,:,:,:,m] = sup\n",
    "\n",
    "# Normalize all features\n",
    "features = preprocess_features(features)\n",
    "\n",
    "# Test processed inputs\n",
    "test_inputs(features, support_tensor, y_arr)\n",
    "\n",
    "# Define placeholders\n",
    "F = features.shape[2]\n",
    "placeholders = {\n",
    "    'support': tf.placeholder(tf.float32, shape=(None,num_supports,N,N,M)), # ?xnum_supportsxNxNxM\n",
    "    'features': tf.placeholder(tf.float32, shape=(None,N,F)), # ?xNxF\n",
    "    'labels': tf.placeholder(tf.float32, shape=(None, y_arr.shape[1])), # ?,|labels|\n",
    "    'dropout': tf.placeholder_with_default(0., shape=())\n",
    "}\n",
    "\n",
    "# Define model evaluation function\n",
    "def evaluate(features, support, labels, mask, placeholders, model):\n",
    "    t_test = time.time()\n",
    "    features = features[mask,:,:]\n",
    "    support = support[mask,:,:,:]\n",
    "    labels = labels[mask, :]\n",
    "    feed_dict = construct_feed_dict(features, support, labels, placeholders)\n",
    "    outs_val = sess.run([model.loss, model.accuracy], feed_dict=feed_dict)\n",
    "    return outs_val[0], outs_val[1], (time.time() - t_test)\n",
    "\n",
    "def optimize():\n",
    "    # Train model\n",
    "    print(\"\\nOptimization of Stopping Conditions:\")\n",
    "    t = time.time()\n",
    "    cost_ls = []\n",
    "    last_improvement = 0\n",
    "    best_accuracy = 0\n",
    "    improved_str = ''\n",
    "    for epoch in range(FLAGS.epochs):\n",
    "        t_epoch = time.time()\n",
    "        # Instantiate all inputs\n",
    "        features_train = features[train_mask,:,:]\n",
    "        support = support_tensor[train_mask,:,:,:]\n",
    "        y_train = y_arr[train_mask, :]\n",
    "        # Construct feed dictionary\n",
    "        feed_dict = construct_feed_dict(features_train, support, y_train, placeholders)\n",
    "        feed_dict.update({placeholders['dropout']: FLAGS.dropout})\n",
    "        # Reset the counters\n",
    "        sess.run(model.running_vars_initializer)\n",
    "        # Training step\n",
    "        outs = sess.run([model.opt_op, model.loss, model.accuracy], feed_dict=feed_dict)\n",
    "        # Reset the counters\n",
    "        sess.run(model.running_vars_initializer)\n",
    "        # Validation evaluation\n",
    "        cost, acc, duration = evaluate(features, support_tensor, y_arr, val_mask, placeholders, model)\n",
    "        cost_ls.append(cost)\n",
    "        # Save the model IF validation is sufficiently accurate\n",
    "        if acc > best_accuracy:\n",
    "            best_accuracy = acc\n",
    "            last_improvement = epoch\n",
    "            saver.save(sess=sess, save_path=save_path_val)\n",
    "            improved_str += '*'\n",
    "        # Print results\n",
    "        if (epoch + 1) % 20 == 0:\n",
    "            print(\"Epoch:\", '%04d' % (epoch + 1), \"train_loss=\", \"{:.5f}\".format(outs[1]),\"train_acc=\", \"{:.5f}\".format(outs[2]),\n",
    "                  \"val_loss=\", \"{:.5f}\".format(cost), \"val_acc=\", \"{:.5f}\".format(acc),\"time=\", \"{:.5f}\".format(time.time() - t), improved_str)\n",
    "            t = time.time()\n",
    "            improved_str = ''\n",
    "        if epoch > FLAGS.early_stopping and epoch - last_improvement > 200:\n",
    "            print(\"Early stopping...\")\n",
    "            break\n",
    "    print(\"Optimization Finished! Total Time: {} sec\".format(time.time() - ttot))\n",
    "    return best_accuracy, epoch\n",
    "\n",
    "def testing_results(epoch_final):\n",
    "    # Initialize session\n",
    "    print(\"\\nTraining on test set:\")\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(model.running_vars_initializer)\n",
    "    # Combine training and validation\n",
    "    mask = np.array([x or y for (x,y) in zip(test_mask, val_mask)], dtype = np.bool)\n",
    "    # Train model\n",
    "    t = time.time()\n",
    "    cost_ls = []\n",
    "    last_improvement = 0\n",
    "    best_accuracy = 0\n",
    "    improved_str = ''\n",
    "    for epoch in range(FLAGS.epochs):\n",
    "        t_epoch = time.time()\n",
    "        # Instantiate all inputs\n",
    "        features_train = features[mask,:,:]\n",
    "        support = support_tensor[mask,:,:,:]\n",
    "        y_train = y_arr[mask, :]\n",
    "        # Construct feed dictionary\n",
    "        feed_dict = construct_feed_dict(features_train, support, y_train, placeholders)\n",
    "        feed_dict.update({placeholders['dropout']: FLAGS.dropout})\n",
    "        # Reset the counters\n",
    "        sess.run(model.running_vars_initializer)\n",
    "        # Training step\n",
    "        outs = sess.run([model.opt_op, model.loss, model.accuracy], feed_dict=feed_dict)\n",
    "        # Reset the counters\n",
    "        sess.run(model.running_vars_initializer)\n",
    "        # Evaluate\n",
    "        cost, acc, duration = evaluate(features, support_tensor, y_arr, test_mask, placeholders, model)\n",
    "        cost_ls.append(cost)\n",
    "        epoch_df.iloc[epoch, :] = [outs[1], outs[2], cost, acc, time.time() - t_epoch]\n",
    "        # Save the model IF training accuracy is a maximum\n",
    "        if outs[2] > best_accuracy:\n",
    "            best_accuracy = outs[2]\n",
    "            last_improvement = epoch\n",
    "            saver.save(sess=sess, save_path=save_path_test)\n",
    "            improved_str += '*'\n",
    "        # Print results\n",
    "        if (epoch + 1) % 20 == 0:\n",
    "            print(\"Epoch:\", '%04d' % (epoch + 1), \"train_loss=\", \"{:.5f}\".format(outs[1]),\"train_acc=\", \"{:.5f}\".format(outs[2]),\n",
    "                  \"test_loss=\", \"{:.5f}\".format(cost), \"test_acc=\", \"{:.5f}\".format(acc),\"time=\", \"{:.5f}\".format(time.time() - t), improved_str)\n",
    "            improved_str = ''\n",
    "            t = time.time()\n",
    "        # Stop training when we hit old epoch number \n",
    "        if epoch > epoch_final and epoch - last_improvement > 200:\n",
    "            print(\"Early stopping...\")\n",
    "            break\n",
    "    print(\"Optimization for Test Finished! Total Time: {} sec\".format(time.time() - ttot))\n",
    "    return best_accuracy\n",
    "\n",
    "# Create model\n",
    "model = model_func(placeholders, input_dim=features.shape[2], logging=True)\n",
    "\n",
    "# Initialize session\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(model.running_vars_initializer)\n",
    "\n",
    "# Make saver\n",
    "saver = tf.train.Saver()\n",
    "save_dir = 'checkpoints/'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "num = random.randint(100000,999999)\n",
    "save_path_val = os.path.join(save_dir, f'best_validation_{num}')\n",
    "save_path_val = os.path.join(os.getcwd(), save_path_val)\n",
    "save_path_test = os.path.join(save_dir, f'best_training_{num}')\n",
    "save_path_test = os.path.join(os.getcwd(), save_path_test)\n",
    "\n",
    "# Do optimization on validation set\n",
    "accuracy_validation, final_epoch = optimize()\n",
    "\n",
    "# Validation\n",
    "if save_validation:\n",
    "    root = os.getcwd()\n",
    "    os.chdir('..')\n",
    "    results = os.path.join(os.getcwd(), \"Results\")\n",
    "    os.chdir(root)\n",
    "    txt = os.path.join(results, \"validation_results.txt\")\n",
    "    if not os.path.exists(txt):\n",
    "        with open(txt, \"w+\") as fh:\n",
    "            fh.write(\"Dataset\\tTest Dataset\\tValidation Accuracy\\tMax Epochs\\tFinal Epoch\\tModel\\tMax Degree\\tLearning Rate\\tDropout\\t\")\n",
    "            fh.write(\"Attention Dimension\\tAttention Bias\\tGraph Convolution Dimensions\\tFully Connected Dimensions\\t\")\n",
    "            fh.write(\"Balanced Training\\tWeight Decay\\tEarly Stopping\\n\")\n",
    "    vals = [FLAGS.dataset, FLAGS.test_dataset, accuracy_validation, FLAGS.epochs,final_epoch, FLAGS.model, FLAGS.max_degree,\n",
    "            FLAGS.learning_rate, FLAGS.dropout, FLAGS.attention_dim, FLAGS.attention_bias, FLAGS.graph_conv_dimensions,\n",
    "            FLAGS.connected_dimensions, FLAGS.balanced_training, FLAGS.weight_decay, FLAGS.early_stopping]\n",
    "    with open(txt, \"a\") as fh:\n",
    "        string = \"\"\n",
    "        for val in vals: string += str(val) + \"\\t\"\n",
    "        fh.write(string + \"\\n\")\n",
    "\n",
    "# Test\n",
    "if save_test:\n",
    "    # Train on validation and train set\n",
    "    accuracy_train = testing_results(final_epoch)\n",
    "    # Choose which model to use\n",
    "    if accuracy_validation > accuracy_train:\n",
    "        path = save_path_val\n",
    "    else:\n",
    "        path = save_path_test\n",
    "    # Load model\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver.restore(sess=sess, save_path=path)\n",
    "    # Evaluate\n",
    "    test_cost, test_acc, test_duration = evaluate(features, support_tensor, y_arr, test_mask, placeholders, model)\n",
    "    print(\"Test set results:\", \"cost=\", \"{:.5f}\".format(test_cost),\n",
    "      \"accuracy=\", \"{:.5f}\".format(test_acc), \"time=\", \"{:.5f}\".format(test_duration))\n",
    "    # Saving results to a file\n",
    "    epoch_df.columns = [\"train_loss\", \"train_acc\", \"test_loss\", \"test_acc\", \"time\"]\n",
    "    labels_df.columns = [\"Sequence\", \"Label\", \"Prediction\", \"Negative Class Logit\", \"Positive Class Logit\"]\n",
    "    # get test values\n",
    "    features_test = features[test_mask,:,:]\n",
    "    support_test = support_tensor[test_mask,:,:,:]\n",
    "    labels_test = y_arr[test_mask, :]\n",
    "    # add sequences\n",
    "    labels_df.iloc[:, 0] = [sequences[i] for i in range(len(test_mask)) if test_mask[i]]\n",
    "    # add true labels\n",
    "    labels_df.iloc[:, 1] = [np.where(labels_test[i])[0] for i in range((sum(test_mask)))]\n",
    "    # get logits in final layer and attention layer values\n",
    "    feed_dict = construct_feed_dict(features_test, support_test, labels_test, placeholders)\n",
    "    logits, predictions, attentions = sess.run([model.logits, model.predictions, model.attentions], feed_dict=feed_dict)\n",
    "    labels_df.iloc[:, 3:5] = logits\n",
    "    # get predictions\n",
    "    labels_df.iloc[:, 2] = predictions\n",
    "    # add attentions\n",
    "    att = np.zeros(shape = (attentions.shape[0] * attentions.shape[1], attentions.shape[2]))\n",
    "    for bat in range(attentions.shape[0]):\n",
    "        att[bat*attentions.shape[1]:(bat + 1)*attentions.shape[1],:] = attentions[bat,:,:]\n",
    "    attention_df = pd.DataFrame(att)\n",
    "    seq_test = [sequences[i] for i in range(len(test_mask)) if test_mask[i]]\n",
    "    bias_vals = []\n",
    "    batch_vals = []\n",
    "    s = []\n",
    "    for i in range(attentions.shape[0]): bias_vals += list(range(attentions.shape[1]))\n",
    "    for i in range(attentions.shape[0]): batch_vals += [i for j in range(attentions.shape[1])]\n",
    "    for i in range(attentions.shape[0]): s += [seq_test[i] for j in range(attentions.shape[1])]\n",
    "    attention_df[\"Bias\"] = bias_vals\n",
    "    attention_df[\"Batch\"] = batch_vals\n",
    "    attention_df[\"Sequence\"] = s\n",
    "    attention_df[\"N\"] = attentions.shape[2]\n",
    "    # change indices for labels to their names\n",
    "    labels_df.iloc[:,1] = labels_df.iloc[:,1].map(lambda x: labelorder[x])\n",
    "    labels_df.iloc[:,2] = labels_df.iloc[:,2].map(lambda x: labelorder[x])\n",
    "    # write to file\n",
    "    if FLAGS.test_dataset != \"testset\":\n",
    "        datadesc = \"train_\" + FLAGS.dataset + \"_test_\" + FLAGS.test_dataset\n",
    "    else:\n",
    "        datadesc = FLAGS.dataset\n",
    "    epoch_df.to_csv(\"../Results/{}.{}.epoch.csv\".format(model_desc, datadesc), index = False)\n",
    "    labels_df.to_csv(\"../Results/{}.{}.predictions.csv\".format(model_desc, datadesc), index = False)\n",
    "    attention_df.to_csv(\"../Results/{}.{}.attentions.csv\".format(model_desc, datadesc), index = False)\n",
    "\n",
    "for file in os.listdir(save_dir):\n",
    "    if str(num) in file:\n",
    "        os.remove(os.path.join(save_dir, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph: [selector_8_ang_ratio_0_params_all_onehot_distance,selector_8_ang_ratio_0_params_all_onehot_distance], testset\n",
      "Model lr_0.01_epoch_20_stop_500_gc_[20]_do_0.0_ad_10_ab_2_fc_[]_m_gcn_deg_1\n",
      "|Training| 1992, |Validation| 332, |Testing| 996\n",
      "Preprocessing adjacency lists\n",
      "2019-07-29 18:49:10.598432: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "\n",
      "Optimization of Stopping Conditions:\n",
      "Epoch: 0020 train_loss= 1.39334 train_acc= 0.25251 val_loss= 1.39248 val_acc= 0.29217 time= 16.72855 *\n",
      "Optimization Finished! Total Time: 19.015727043151855 sec\n"
     ]
    }
   ],
   "source": [
    "!python3 train.py -balanced_training True -learning_rate .01 -epochs 20 -early_stopping 500 -graph_conv_dimensions [20] -connected_dimensions [] -dropout 0 -attention_dim 10 -attention_bias 2 -model gcn -max_degree 1 -dataset [selector_8_ang_ratio_0_params_all_onehot_distance,selector_8_ang_ratio_0_params_all_onehot_distance] -save_test False -save_validation True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph selector_8_ang_ratio_0_params_all_onehot_distance, testset\n",
      "Model lr_0.01_epoch_200_stop_200_gc_[20,20]_do_0.0_ad_10_ab_3_fc_[10,10]_m_gcn_cheby_deg_3\n",
      "|Training| 996, |Validation| 166, |Testing| 498\n",
      "Calculating Chebyshev polynomials up to order 3...\n",
      "/mnt/c/Users/Owner/Documents/Code/Research_Scripts/PyRosetta/Graph-Convolutional-Neural-Network/Model/utils.py:119: RuntimeWarning: divide by zero encountered in power\n",
      "  d_inv_sqrt = np.power(rowsum, -0.5).flatten()\n",
      "2019-07-29 18:30:34.379600: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "\n",
      "Optimization of Stopping Conditions:\n",
      "Epoch: 0020 train_loss= 0.72028 train_acc= 0.27108 val_loss= 0.71686 val_acc= 0.25301 time= 25.53053 *\n",
      "Epoch: 0040 train_loss= 0.61815 train_acc= 0.72892 val_loss= 0.58798 val_acc= 0.74699 time= 26.86422 **\n",
      "Epoch: 0060 train_loss= 0.58068 train_acc= 0.72892 val_loss= 0.56265 val_acc= 0.74699 time= 26.78343 \n",
      "Epoch: 0080 train_loss= 0.45686 train_acc= 0.78614 val_loss= 0.52249 val_acc= 0.76506 time= 27.19014 *\n",
      "Epoch: 0100 train_loss= 0.39590 train_acc= 0.80221 val_loss= 0.42050 val_acc= 0.83735 time= 28.18927 **\n",
      "Epoch: 0120 train_loss= 0.34992 train_acc= 0.85643 val_loss= 0.40158 val_acc= 0.84940 time= 35.36082 \n",
      "Epoch: 0140 train_loss= 0.37299 train_acc= 0.83936 val_loss= 0.41193 val_acc= 0.81325 time= 33.14739 \n",
      "Epoch: 0160 train_loss= 0.33475 train_acc= 0.85442 val_loss= 0.40693 val_acc= 0.82530 time= 32.37054 \n",
      "Epoch: 0180 train_loss= 0.33296 train_acc= 0.85944 val_loss= 0.38208 val_acc= 0.81325 time= 32.44959 \n",
      "Epoch: 0200 train_loss= 0.31534 train_acc= 0.87550 val_loss= 0.43139 val_acc= 0.84940 time= 33.39847 \n",
      "Optimization Finished! Total Time: 321.563419342041 sec\n",
      "\n",
      "Training on test set:\n",
      "Epoch: 0020 train_loss= 0.61217 train_acc= 0.76506 test_loss= 0.59666 test_acc= 0.77108 time= 33.55839 **\n",
      "Epoch: 0040 train_loss= 0.56201 train_acc= 0.76506 test_loss= 0.55380 test_acc= 0.77108 time= 32.40968 \n",
      "Epoch: 0060 train_loss= 0.49758 train_acc= 0.76506 test_loss= 0.48672 test_acc= 0.77108 time= 35.77340 \n",
      "Epoch: 0080 train_loss= 0.39075 train_acc= 0.83886 test_loss= 0.37872 test_acc= 0.84940 time= 35.27971 ****\n",
      "Epoch: 0100 train_loss= 0.40522 train_acc= 0.81325 test_loss= 0.40935 test_acc= 0.81124 time= 33.76153 ***\n",
      "Epoch: 0120 train_loss= 0.33240 train_acc= 0.87199 test_loss= 0.32854 test_acc= 0.87751 time= 32.85133 **\n",
      "Epoch: 0140 train_loss= 0.27419 train_acc= 0.90663 test_loss= 0.27962 test_acc= 0.89759 time= 38.19559 ********\n",
      "Epoch: 0160 train_loss= 0.25170 train_acc= 0.91867 test_loss= 0.26441 test_acc= 0.90964 time= 36.74501 ***\n",
      "Epoch: 0180 train_loss= 0.23000 train_acc= 0.92018 test_loss= 0.22209 test_acc= 0.92972 time= 39.67037 ****\n",
      "Epoch: 0200 train_loss= 0.19671 train_acc= 0.94127 test_loss= 0.19226 test_acc= 0.94578 time= 33.40563 ****\n",
      "Optimization for Test Finished! Total Time: 673.5393061637878 sec\n",
      "Test set results: cost= 0.23816 accuracy= 0.92972 time= 0.47482\n"
     ]
    }
   ],
   "source": [
    "!python3 train.py -learning_rate 0.01 -epochs 20 -early_stopping 200 -graph_conv_dimensions [20,20] -dropout 0 -attention_dim 10 -attention_bias 3 -model gcn_cheby -max_degree 3 -connected_dimensions [10,10] -dataset selector_8_ang_ratio_0_params_all_onehot_distance -save_test True -save_validation False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 46.9 ms, sys: 46.9 ms, total: 93.8 ms\n",
      "Wall time: 1.72 s\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "%time !python3 consolidate_results.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 1.]]\n",
      "(26, 26)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([1.]), array([[ 0.06820068],\n",
       "        [ 0.05824877],\n",
       "        [-0.15169597],\n",
       "        [ 0.03231936],\n",
       "        [ 0.0931789 ],\n",
       "        [ 0.00290181],\n",
       "        [ 0.06703742],\n",
       "        [ 0.36320261],\n",
       "        [-0.26347516],\n",
       "        [-0.05083581],\n",
       "        [-0.10620215],\n",
       "        [ 0.25611725],\n",
       "        [-0.12235471],\n",
       "        [ 0.20537812],\n",
       "        [ 0.30986563],\n",
       "        [ 0.24861462],\n",
       "        [-0.13556621],\n",
       "        [ 0.02169414],\n",
       "        [-0.12080429],\n",
       "        [ 0.45722021],\n",
       "        [-0.14662624],\n",
       "        [ 0.0022738 ],\n",
       "        [-0.13244341],\n",
       "        [ 0.02799337],\n",
       "        [ 0.37835751],\n",
       "        [ 0.18293973]]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse.linalg.eigen.arpack import eigsh\n",
    "laplacian = np.identity(26)\n",
    "print(type(laplacian))\n",
    "print(laplacian)\n",
    "print(laplacian.shape)\n",
    "eigsh(laplacian, 1, which='LM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Test Dataset</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <th>Max Epochs</th>\n",
       "      <th>Final Epoch</th>\n",
       "      <th>Model</th>\n",
       "      <th>Max Degree</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Dropout</th>\n",
       "      <th>Attention Dimension</th>\n",
       "      <th>Attention Bias</th>\n",
       "      <th>Graph Convolution Dimensions</th>\n",
       "      <th>Fully Connected Dimensions</th>\n",
       "      <th>Balanced Training</th>\n",
       "      <th>Weight Decay</th>\n",
       "      <th>Early Stopping</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[protease_HCV_selector_k_nearest_ratio_0_param...</td>\n",
       "      <td>testset</td>\n",
       "      <td>0.902166</td>\n",
       "      <td>1000</td>\n",
       "      <td>557</td>\n",
       "      <td>gcn_cheby</td>\n",
       "      <td>3</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>[20,]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>protease_HCV_selector_k_nearest_ratio_0_params_0</td>\n",
       "      <td>testset</td>\n",
       "      <td>0.900545</td>\n",
       "      <td>1000</td>\n",
       "      <td>464</td>\n",
       "      <td>gcn_cheby</td>\n",
       "      <td>3</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>[20,]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>protease_HCV_A171T_selector_k_nearest_ratio_0_...</td>\n",
       "      <td>testset</td>\n",
       "      <td>0.938683</td>\n",
       "      <td>1000</td>\n",
       "      <td>407</td>\n",
       "      <td>gcn_cheby</td>\n",
       "      <td>3</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>[20,]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>protease_HCV_D183A_selector_k_nearest_ratio_0_...</td>\n",
       "      <td>testset</td>\n",
       "      <td>0.885329</td>\n",
       "      <td>1000</td>\n",
       "      <td>401</td>\n",
       "      <td>gcn_cheby</td>\n",
       "      <td>3</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>[20,]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>protease_HCV_R170K_A171T_D183A_selector_k_near...</td>\n",
       "      <td>testset</td>\n",
       "      <td>0.913743</td>\n",
       "      <td>1000</td>\n",
       "      <td>381</td>\n",
       "      <td>gcn_cheby</td>\n",
       "      <td>3</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>[20,]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[protease_HCV_selector_k_nearest_ratio_0_param...</td>\n",
       "      <td>testset</td>\n",
       "      <td>0.905733</td>\n",
       "      <td>1000</td>\n",
       "      <td>479</td>\n",
       "      <td>gcn_cheby</td>\n",
       "      <td>3</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>[20,]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[protease_HCV_selector_k_nearest_ratio_0_param...</td>\n",
       "      <td>testset</td>\n",
       "      <td>0.338853</td>\n",
       "      <td>1000</td>\n",
       "      <td>201</td>\n",
       "      <td>gcn_cheby</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>[10,]</td>\n",
       "      <td>[20,20,]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[protease_HCV_selector_k_nearest_ratio_0_param...</td>\n",
       "      <td>testset</td>\n",
       "      <td>0.338853</td>\n",
       "      <td>1000</td>\n",
       "      <td>201</td>\n",
       "      <td>gcn_cheby</td>\n",
       "      <td>3</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>[10,]</td>\n",
       "      <td>[20,20,]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[protease_HCV_selector_k_nearest_ratio_0_param...</td>\n",
       "      <td>testset</td>\n",
       "      <td>0.338853</td>\n",
       "      <td>1000</td>\n",
       "      <td>201</td>\n",
       "      <td>gcn_cheby</td>\n",
       "      <td>3</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>[10,10,]</td>\n",
       "      <td>[20,20,]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>protease_HCV_selector_k_nearest_ratio_0_params_0</td>\n",
       "      <td>testset</td>\n",
       "      <td>0.280654</td>\n",
       "      <td>1000</td>\n",
       "      <td>201</td>\n",
       "      <td>gcn_cheby</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>[10,]</td>\n",
       "      <td>[20,20,]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>protease_HCV_selector_k_nearest_ratio_0_params_1</td>\n",
       "      <td>testset</td>\n",
       "      <td>0.280654</td>\n",
       "      <td>1000</td>\n",
       "      <td>201</td>\n",
       "      <td>gcn_cheby</td>\n",
       "      <td>3</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>[10,]</td>\n",
       "      <td>[20,20,]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>protease_HCV_selector_k_nearest_ratio_0_params_0</td>\n",
       "      <td>testset</td>\n",
       "      <td>0.893733</td>\n",
       "      <td>1000</td>\n",
       "      <td>401</td>\n",
       "      <td>gcn_cheby</td>\n",
       "      <td>3</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>[20,]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>protease_HCV_selector_k_nearest_ratio_0_params_0</td>\n",
       "      <td>testset</td>\n",
       "      <td>0.280654</td>\n",
       "      <td>1000</td>\n",
       "      <td>201</td>\n",
       "      <td>gcn_cheby</td>\n",
       "      <td>3</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>[10,10,]</td>\n",
       "      <td>[20,20,]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>protease_HCV_A171T_selector_k_nearest_ratio_0_...</td>\n",
       "      <td>testset</td>\n",
       "      <td>0.283876</td>\n",
       "      <td>1000</td>\n",
       "      <td>201</td>\n",
       "      <td>gcn_cheby</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>[10,]</td>\n",
       "      <td>[20,20,]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[protease_HCV_selector_k_nearest_ratio_0_param...</td>\n",
       "      <td>testset</td>\n",
       "      <td>0.338853</td>\n",
       "      <td>1000</td>\n",
       "      <td>201</td>\n",
       "      <td>gcn_cheby</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>[10,10,]</td>\n",
       "      <td>[20,20,]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>protease_HCV_A171T_selector_k_nearest_ratio_0_...</td>\n",
       "      <td>testset</td>\n",
       "      <td>0.283876</td>\n",
       "      <td>1000</td>\n",
       "      <td>201</td>\n",
       "      <td>gcn_cheby</td>\n",
       "      <td>3</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>[10,]</td>\n",
       "      <td>[20,20,]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[protease_HCV_selector_k_nearest_ratio_0_param...</td>\n",
       "      <td>testset</td>\n",
       "      <td>0.338853</td>\n",
       "      <td>1000</td>\n",
       "      <td>201</td>\n",
       "      <td>gcn_cheby</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>[20,20,]</td>\n",
       "      <td>[20,]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[protease_HCV_selector_k_nearest_ratio_0_param...</td>\n",
       "      <td>testset</td>\n",
       "      <td>0.338853</td>\n",
       "      <td>1000</td>\n",
       "      <td>201</td>\n",
       "      <td>gcn_cheby</td>\n",
       "      <td>3</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>[20,20,]</td>\n",
       "      <td>[20,]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>protease_HCV_A171T_selector_k_nearest_ratio_0_...</td>\n",
       "      <td>testset</td>\n",
       "      <td>0.283876</td>\n",
       "      <td>1000</td>\n",
       "      <td>201</td>\n",
       "      <td>gcn_cheby</td>\n",
       "      <td>3</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>[10,10,]</td>\n",
       "      <td>[20,20,]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>protease_HCV_D183A_selector_k_nearest_ratio_0_...</td>\n",
       "      <td>testset</td>\n",
       "      <td>0.362563</td>\n",
       "      <td>1000</td>\n",
       "      <td>201</td>\n",
       "      <td>gcn_cheby</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>[10,]</td>\n",
       "      <td>[20,20,]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[protease_HCV_selector_k_nearest_ratio_0_param...</td>\n",
       "      <td>testset</td>\n",
       "      <td>0.811465</td>\n",
       "      <td>1000</td>\n",
       "      <td>293</td>\n",
       "      <td>gcn_cheby</td>\n",
       "      <td>3</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>[10,10,]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>protease_HCV_selector_k_nearest_ratio_0_params_1</td>\n",
       "      <td>testset</td>\n",
       "      <td>0.280654</td>\n",
       "      <td>1000</td>\n",
       "      <td>201</td>\n",
       "      <td>gcn_cheby</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>[10,10,]</td>\n",
       "      <td>[20,20,]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[protease_HCV_selector_k_nearest_ratio_0_param...</td>\n",
       "      <td>testset</td>\n",
       "      <td>0.812229</td>\n",
       "      <td>1000</td>\n",
       "      <td>320</td>\n",
       "      <td>gcn_cheby</td>\n",
       "      <td>3</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>[10,10,]</td>\n",
       "      <td>[20,]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[protease_HCV_selector_k_nearest_ratio_0_param...</td>\n",
       "      <td>testset</td>\n",
       "      <td>0.905733</td>\n",
       "      <td>1000</td>\n",
       "      <td>421</td>\n",
       "      <td>gcn_cheby</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>[10,]</td>\n",
       "      <td>[20,]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>protease_HCV_selector_k_nearest_ratio_0_params_1</td>\n",
       "      <td>testset</td>\n",
       "      <td>0.280654</td>\n",
       "      <td>1000</td>\n",
       "      <td>201</td>\n",
       "      <td>gcn_cheby</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>[20,20,]</td>\n",
       "      <td>[20,]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>protease_HCV_A171T_selector_k_nearest_ratio_0_...</td>\n",
       "      <td>testset</td>\n",
       "      <td>0.937169</td>\n",
       "      <td>1000</td>\n",
       "      <td>335</td>\n",
       "      <td>gcn_cheby</td>\n",
       "      <td>3</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>[20,]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[protease_HCV_selector_k_nearest_ratio_0_param...</td>\n",
       "      <td>testset</td>\n",
       "      <td>0.338853</td>\n",
       "      <td>1000</td>\n",
       "      <td>201</td>\n",
       "      <td>gcn_cheby</td>\n",
       "      <td>3</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>[20,20,20,]</td>\n",
       "      <td>[20,20,]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>protease_HCV_selector_k_nearest_ratio_0_params_0</td>\n",
       "      <td>testset</td>\n",
       "      <td>0.280654</td>\n",
       "      <td>1000</td>\n",
       "      <td>201</td>\n",
       "      <td>gcn_cheby</td>\n",
       "      <td>3</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>[20,20,]</td>\n",
       "      <td>[20,]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[protease_HCV_selector_k_nearest_ratio_0_param...</td>\n",
       "      <td>testset</td>\n",
       "      <td>0.907261</td>\n",
       "      <td>1000</td>\n",
       "      <td>436</td>\n",
       "      <td>gcn_cheby</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>[10,10,]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>protease_HCV_D183A_selector_k_nearest_ratio_0_...</td>\n",
       "      <td>testset</td>\n",
       "      <td>0.802698</td>\n",
       "      <td>1000</td>\n",
       "      <td>440</td>\n",
       "      <td>gcn_cheby</td>\n",
       "      <td>3</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>[10,]</td>\n",
       "      <td>[20,20,]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6193</th>\n",
       "      <td>protease_HCV_R170K_A171T_D183A_selector_k_near...</td>\n",
       "      <td>testset</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>1000</td>\n",
       "      <td>336</td>\n",
       "      <td>gcn_cheby</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>[10,10,]</td>\n",
       "      <td>[20,]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6194</th>\n",
       "      <td>protease_HCV_D183A_selector_k_nearest_ratio_0_...</td>\n",
       "      <td>testset</td>\n",
       "      <td>0.893761</td>\n",
       "      <td>1000</td>\n",
       "      <td>296</td>\n",
       "      <td>gcn_cheby</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>[20,20,]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6195</th>\n",
       "      <td>protease_HCV_selector_8_ang_ratio_0_params_3</td>\n",
       "      <td>testset</td>\n",
       "      <td>0.911444</td>\n",
       "      <td>1000</td>\n",
       "      <td>963</td>\n",
       "      <td>gcn_cheby</td>\n",
       "      <td>3</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>[20,20,]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6196</th>\n",
       "      <td>[protease_HCV_selector_10_ang_ratio_0_params_2...</td>\n",
       "      <td>testset</td>\n",
       "      <td>0.852994</td>\n",
       "      <td>1000</td>\n",
       "      <td>881</td>\n",
       "      <td>gcn_cheby</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>[20,]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6197</th>\n",
       "      <td>protease_HCV_selector_8_ang_ratio_0_params_0</td>\n",
       "      <td>testset</td>\n",
       "      <td>0.896458</td>\n",
       "      <td>1000</td>\n",
       "      <td>731</td>\n",
       "      <td>gcn_cheby</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>[10,10,]</td>\n",
       "      <td>[20,]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6198</th>\n",
       "      <td>[protease_HCV_selector_10_ang_ratio_0_params_1...</td>\n",
       "      <td>testset</td>\n",
       "      <td>0.795924</td>\n",
       "      <td>1000</td>\n",
       "      <td>603</td>\n",
       "      <td>gcn_cheby</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>[10,10,10,]</td>\n",
       "      <td>[20,]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6199</th>\n",
       "      <td>protease_HCV_D183A_selector_8_ang_ratio_0_para...</td>\n",
       "      <td>testset</td>\n",
       "      <td>0.798482</td>\n",
       "      <td>1000</td>\n",
       "      <td>988</td>\n",
       "      <td>gcn_cheby</td>\n",
       "      <td>3</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>[20,]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6200</th>\n",
       "      <td>protease_HCV_R170K_A171T_D183A_selector_10_ang...</td>\n",
       "      <td>testset</td>\n",
       "      <td>0.438597</td>\n",
       "      <td>1000</td>\n",
       "      <td>201</td>\n",
       "      <td>gcn_cheby</td>\n",
       "      <td>3</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>[20,20,]</td>\n",
       "      <td>[20,20,]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6201</th>\n",
       "      <td>protease_HCV_A171T_selector_8_ang_ratio_0_para...</td>\n",
       "      <td>testset</td>\n",
       "      <td>0.831946</td>\n",
       "      <td>1000</td>\n",
       "      <td>287</td>\n",
       "      <td>gcn_cheby</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>[20,]</td>\n",
       "      <td>[20,]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6202</th>\n",
       "      <td>protease_HCV_selector_10_ang_ratio_0_params_1</td>\n",
       "      <td>testset</td>\n",
       "      <td>0.719346</td>\n",
       "      <td>1000</td>\n",
       "      <td>204</td>\n",
       "      <td>gcn_cheby</td>\n",
       "      <td>3</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>[10,10,]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6203</th>\n",
       "      <td>protease_HCV_A171T_selector_8_ang_ratio_0_para...</td>\n",
       "      <td>testset</td>\n",
       "      <td>0.897805</td>\n",
       "      <td>1000</td>\n",
       "      <td>999</td>\n",
       "      <td>gcn_cheby</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>[10,]</td>\n",
       "      <td>[20,]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6204</th>\n",
       "      <td>protease_HCV_A171T_selector_8_ang_ratio_0_para...</td>\n",
       "      <td>testset</td>\n",
       "      <td>0.866011</td>\n",
       "      <td>1000</td>\n",
       "      <td>494</td>\n",
       "      <td>gcn_cheby</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>[10,10,10,]</td>\n",
       "      <td>[20,]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6205</th>\n",
       "      <td>protease_HCV_selector_10_ang_ratio_0_params_1</td>\n",
       "      <td>testset</td>\n",
       "      <td>0.805177</td>\n",
       "      <td>1000</td>\n",
       "      <td>647</td>\n",
       "      <td>gcn_cheby</td>\n",
       "      <td>3</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>[10,10,]</td>\n",
       "      <td>[20,]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6206</th>\n",
       "      <td>protease_HCV_R170K_A171T_D183A_selector_k_near...</td>\n",
       "      <td>testset</td>\n",
       "      <td>0.438597</td>\n",
       "      <td>1000</td>\n",
       "      <td>201</td>\n",
       "      <td>gcn_cheby</td>\n",
       "      <td>3</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>[10,10,10,]</td>\n",
       "      <td>[20,]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6207</th>\n",
       "      <td>[protease_HCV_selector_10_ang_ratio_0_params_0...</td>\n",
       "      <td>testset</td>\n",
       "      <td>0.338853</td>\n",
       "      <td>1000</td>\n",
       "      <td>201</td>\n",
       "      <td>gcn_cheby</td>\n",
       "      <td>3</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>[10,10,]</td>\n",
       "      <td>[20,20,]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6208</th>\n",
       "      <td>protease_HCV_A171T_selector_10_ang_ratio_0_par...</td>\n",
       "      <td>testset</td>\n",
       "      <td>0.834974</td>\n",
       "      <td>1000</td>\n",
       "      <td>705</td>\n",
       "      <td>gcn_cheby</td>\n",
       "      <td>3</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>[10,10,10,]</td>\n",
       "      <td>[20,20,]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6209</th>\n",
       "      <td>protease_HCV_A171T_selector_8_ang_ratio_0_para...</td>\n",
       "      <td>testset</td>\n",
       "      <td>0.933384</td>\n",
       "      <td>1000</td>\n",
       "      <td>999</td>\n",
       "      <td>gcn_cheby</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>[20,20,]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6210</th>\n",
       "      <td>[protease_HCV_selector_10_ang_ratio_0_params_1...</td>\n",
       "      <td>testset</td>\n",
       "      <td>0.338853</td>\n",
       "      <td>1000</td>\n",
       "      <td>201</td>\n",
       "      <td>gcn_cheby</td>\n",
       "      <td>3</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>[10,10,]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6211</th>\n",
       "      <td>protease_HCV_selector_10_ang_ratio_0_params_0</td>\n",
       "      <td>testset</td>\n",
       "      <td>0.859673</td>\n",
       "      <td>1000</td>\n",
       "      <td>641</td>\n",
       "      <td>gcn_cheby</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>[20,20,]</td>\n",
       "      <td>[20,]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6212</th>\n",
       "      <td>protease_HCV_selector_k_nearest_ratio_0_params_3</td>\n",
       "      <td>testset</td>\n",
       "      <td>0.904632</td>\n",
       "      <td>1000</td>\n",
       "      <td>348</td>\n",
       "      <td>gcn_cheby</td>\n",
       "      <td>3</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>[10,10,10,]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6213</th>\n",
       "      <td>protease_HCV_R170K_A171T_D183A_selector_k_near...</td>\n",
       "      <td>testset</td>\n",
       "      <td>0.921053</td>\n",
       "      <td>1000</td>\n",
       "      <td>796</td>\n",
       "      <td>gcn_cheby</td>\n",
       "      <td>3</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>[10,]</td>\n",
       "      <td>[20,]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6214</th>\n",
       "      <td>protease_HCV_selector_10_ang_ratio_0_params_1</td>\n",
       "      <td>testset</td>\n",
       "      <td>0.799727</td>\n",
       "      <td>1000</td>\n",
       "      <td>675</td>\n",
       "      <td>gcn_cheby</td>\n",
       "      <td>3</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>[10,10,10,]</td>\n",
       "      <td>[20,]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6215</th>\n",
       "      <td>protease_HCV_R170K_A171T_D183A_selector_8_ang_...</td>\n",
       "      <td>testset</td>\n",
       "      <td>0.438597</td>\n",
       "      <td>1000</td>\n",
       "      <td>201</td>\n",
       "      <td>gcn_cheby</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>[20,]</td>\n",
       "      <td>[20,20,]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6216</th>\n",
       "      <td>protease_HCV_R170K_A171T_D183A_selector_k_near...</td>\n",
       "      <td>testset</td>\n",
       "      <td>0.931287</td>\n",
       "      <td>1000</td>\n",
       "      <td>402</td>\n",
       "      <td>gcn_cheby</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>[20,20,]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6217</th>\n",
       "      <td>protease_HCV_A171T_selector_k_nearest_ratio_0_...</td>\n",
       "      <td>testset</td>\n",
       "      <td>0.955337</td>\n",
       "      <td>1000</td>\n",
       "      <td>605</td>\n",
       "      <td>gcn_cheby</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>[20,20,20,]</td>\n",
       "      <td>[20,20,]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6218</th>\n",
       "      <td>protease_HCV_R170K_A171T_D183A_selector_8_ang_...</td>\n",
       "      <td>testset</td>\n",
       "      <td>0.827485</td>\n",
       "      <td>1000</td>\n",
       "      <td>401</td>\n",
       "      <td>gcn_cheby</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>[20,]</td>\n",
       "      <td>[20,20,]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6219</th>\n",
       "      <td>protease_HCV_R170K_A171T_D183A_selector_k_near...</td>\n",
       "      <td>testset</td>\n",
       "      <td>0.890351</td>\n",
       "      <td>1000</td>\n",
       "      <td>380</td>\n",
       "      <td>gcn_cheby</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>[20,20,]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6220</th>\n",
       "      <td>[selector_8_ang_ratio_0_params_all_onehot_dist...</td>\n",
       "      <td>testset</td>\n",
       "      <td>0.292169</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>gcn</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>[20]</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6221</th>\n",
       "      <td>[selector_8_ang_ratio_0_params_all_onehot_dist...</td>\n",
       "      <td>testset</td>\n",
       "      <td>0.292169</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>gcn</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>[20]</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6222</th>\n",
       "      <td>[selector_8_ang_ratio_0_params_all_onehot_dist...</td>\n",
       "      <td>testset</td>\n",
       "      <td>0.292169</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "      <td>gcn</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>[20]</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6223 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Dataset Test Dataset  \\\n",
       "0     [protease_HCV_selector_k_nearest_ratio_0_param...      testset   \n",
       "1      protease_HCV_selector_k_nearest_ratio_0_params_0      testset   \n",
       "2     protease_HCV_A171T_selector_k_nearest_ratio_0_...      testset   \n",
       "3     protease_HCV_D183A_selector_k_nearest_ratio_0_...      testset   \n",
       "4     protease_HCV_R170K_A171T_D183A_selector_k_near...      testset   \n",
       "5     [protease_HCV_selector_k_nearest_ratio_0_param...      testset   \n",
       "6     [protease_HCV_selector_k_nearest_ratio_0_param...      testset   \n",
       "7     [protease_HCV_selector_k_nearest_ratio_0_param...      testset   \n",
       "8     [protease_HCV_selector_k_nearest_ratio_0_param...      testset   \n",
       "9      protease_HCV_selector_k_nearest_ratio_0_params_0      testset   \n",
       "10     protease_HCV_selector_k_nearest_ratio_0_params_1      testset   \n",
       "11     protease_HCV_selector_k_nearest_ratio_0_params_0      testset   \n",
       "12     protease_HCV_selector_k_nearest_ratio_0_params_0      testset   \n",
       "13    protease_HCV_A171T_selector_k_nearest_ratio_0_...      testset   \n",
       "14    [protease_HCV_selector_k_nearest_ratio_0_param...      testset   \n",
       "15    protease_HCV_A171T_selector_k_nearest_ratio_0_...      testset   \n",
       "16    [protease_HCV_selector_k_nearest_ratio_0_param...      testset   \n",
       "17    [protease_HCV_selector_k_nearest_ratio_0_param...      testset   \n",
       "18    protease_HCV_A171T_selector_k_nearest_ratio_0_...      testset   \n",
       "19    protease_HCV_D183A_selector_k_nearest_ratio_0_...      testset   \n",
       "20    [protease_HCV_selector_k_nearest_ratio_0_param...      testset   \n",
       "21     protease_HCV_selector_k_nearest_ratio_0_params_1      testset   \n",
       "22    [protease_HCV_selector_k_nearest_ratio_0_param...      testset   \n",
       "23    [protease_HCV_selector_k_nearest_ratio_0_param...      testset   \n",
       "24     protease_HCV_selector_k_nearest_ratio_0_params_1      testset   \n",
       "25    protease_HCV_A171T_selector_k_nearest_ratio_0_...      testset   \n",
       "26    [protease_HCV_selector_k_nearest_ratio_0_param...      testset   \n",
       "27     protease_HCV_selector_k_nearest_ratio_0_params_0      testset   \n",
       "28    [protease_HCV_selector_k_nearest_ratio_0_param...      testset   \n",
       "29    protease_HCV_D183A_selector_k_nearest_ratio_0_...      testset   \n",
       "...                                                 ...          ...   \n",
       "6193  protease_HCV_R170K_A171T_D183A_selector_k_near...      testset   \n",
       "6194  protease_HCV_D183A_selector_k_nearest_ratio_0_...      testset   \n",
       "6195       protease_HCV_selector_8_ang_ratio_0_params_3      testset   \n",
       "6196  [protease_HCV_selector_10_ang_ratio_0_params_2...      testset   \n",
       "6197       protease_HCV_selector_8_ang_ratio_0_params_0      testset   \n",
       "6198  [protease_HCV_selector_10_ang_ratio_0_params_1...      testset   \n",
       "6199  protease_HCV_D183A_selector_8_ang_ratio_0_para...      testset   \n",
       "6200  protease_HCV_R170K_A171T_D183A_selector_10_ang...      testset   \n",
       "6201  protease_HCV_A171T_selector_8_ang_ratio_0_para...      testset   \n",
       "6202      protease_HCV_selector_10_ang_ratio_0_params_1      testset   \n",
       "6203  protease_HCV_A171T_selector_8_ang_ratio_0_para...      testset   \n",
       "6204  protease_HCV_A171T_selector_8_ang_ratio_0_para...      testset   \n",
       "6205      protease_HCV_selector_10_ang_ratio_0_params_1      testset   \n",
       "6206  protease_HCV_R170K_A171T_D183A_selector_k_near...      testset   \n",
       "6207  [protease_HCV_selector_10_ang_ratio_0_params_0...      testset   \n",
       "6208  protease_HCV_A171T_selector_10_ang_ratio_0_par...      testset   \n",
       "6209  protease_HCV_A171T_selector_8_ang_ratio_0_para...      testset   \n",
       "6210  [protease_HCV_selector_10_ang_ratio_0_params_1...      testset   \n",
       "6211      protease_HCV_selector_10_ang_ratio_0_params_0      testset   \n",
       "6212   protease_HCV_selector_k_nearest_ratio_0_params_3      testset   \n",
       "6213  protease_HCV_R170K_A171T_D183A_selector_k_near...      testset   \n",
       "6214      protease_HCV_selector_10_ang_ratio_0_params_1      testset   \n",
       "6215  protease_HCV_R170K_A171T_D183A_selector_8_ang_...      testset   \n",
       "6216  protease_HCV_R170K_A171T_D183A_selector_k_near...      testset   \n",
       "6217  protease_HCV_A171T_selector_k_nearest_ratio_0_...      testset   \n",
       "6218  protease_HCV_R170K_A171T_D183A_selector_8_ang_...      testset   \n",
       "6219  protease_HCV_R170K_A171T_D183A_selector_k_near...      testset   \n",
       "6220  [selector_8_ang_ratio_0_params_all_onehot_dist...      testset   \n",
       "6221  [selector_8_ang_ratio_0_params_all_onehot_dist...      testset   \n",
       "6222  [selector_8_ang_ratio_0_params_all_onehot_dist...      testset   \n",
       "\n",
       "      Validation Accuracy  Max Epochs  Final Epoch      Model  Max Degree  \\\n",
       "0                0.902166        1000          557  gcn_cheby           3   \n",
       "1                0.900545        1000          464  gcn_cheby           3   \n",
       "2                0.938683        1000          407  gcn_cheby           3   \n",
       "3                0.885329        1000          401  gcn_cheby           3   \n",
       "4                0.913743        1000          381  gcn_cheby           3   \n",
       "5                0.905733        1000          479  gcn_cheby           3   \n",
       "6                0.338853        1000          201  gcn_cheby           3   \n",
       "7                0.338853        1000          201  gcn_cheby           3   \n",
       "8                0.338853        1000          201  gcn_cheby           3   \n",
       "9                0.280654        1000          201  gcn_cheby           3   \n",
       "10               0.280654        1000          201  gcn_cheby           3   \n",
       "11               0.893733        1000          401  gcn_cheby           3   \n",
       "12               0.280654        1000          201  gcn_cheby           3   \n",
       "13               0.283876        1000          201  gcn_cheby           3   \n",
       "14               0.338853        1000          201  gcn_cheby           3   \n",
       "15               0.283876        1000          201  gcn_cheby           3   \n",
       "16               0.338853        1000          201  gcn_cheby           3   \n",
       "17               0.338853        1000          201  gcn_cheby           3   \n",
       "18               0.283876        1000          201  gcn_cheby           3   \n",
       "19               0.362563        1000          201  gcn_cheby           3   \n",
       "20               0.811465        1000          293  gcn_cheby           3   \n",
       "21               0.280654        1000          201  gcn_cheby           3   \n",
       "22               0.812229        1000          320  gcn_cheby           3   \n",
       "23               0.905733        1000          421  gcn_cheby           3   \n",
       "24               0.280654        1000          201  gcn_cheby           3   \n",
       "25               0.937169        1000          335  gcn_cheby           3   \n",
       "26               0.338853        1000          201  gcn_cheby           3   \n",
       "27               0.280654        1000          201  gcn_cheby           3   \n",
       "28               0.907261        1000          436  gcn_cheby           3   \n",
       "29               0.802698        1000          440  gcn_cheby           3   \n",
       "...                   ...         ...          ...        ...         ...   \n",
       "6193             0.888889        1000          336  gcn_cheby           3   \n",
       "6194             0.893761        1000          296  gcn_cheby           3   \n",
       "6195             0.911444        1000          963  gcn_cheby           3   \n",
       "6196             0.852994        1000          881  gcn_cheby           3   \n",
       "6197             0.896458        1000          731  gcn_cheby           3   \n",
       "6198             0.795924        1000          603  gcn_cheby           3   \n",
       "6199             0.798482        1000          988  gcn_cheby           3   \n",
       "6200             0.438597        1000          201  gcn_cheby           3   \n",
       "6201             0.831946        1000          287  gcn_cheby           3   \n",
       "6202             0.719346        1000          204  gcn_cheby           3   \n",
       "6203             0.897805        1000          999  gcn_cheby           3   \n",
       "6204             0.866011        1000          494  gcn_cheby           3   \n",
       "6205             0.805177        1000          647  gcn_cheby           3   \n",
       "6206             0.438597        1000          201  gcn_cheby           3   \n",
       "6207             0.338853        1000          201  gcn_cheby           3   \n",
       "6208             0.834974        1000          705  gcn_cheby           3   \n",
       "6209             0.933384        1000          999  gcn_cheby           3   \n",
       "6210             0.338853        1000          201  gcn_cheby           3   \n",
       "6211             0.859673        1000          641  gcn_cheby           3   \n",
       "6212             0.904632        1000          348  gcn_cheby           3   \n",
       "6213             0.921053        1000          796  gcn_cheby           3   \n",
       "6214             0.799727        1000          675  gcn_cheby           3   \n",
       "6215             0.438597        1000          201  gcn_cheby           3   \n",
       "6216             0.931287        1000          402  gcn_cheby           3   \n",
       "6217             0.955337        1000          605  gcn_cheby           3   \n",
       "6218             0.827485        1000          401  gcn_cheby           3   \n",
       "6219             0.890351        1000          380  gcn_cheby           3   \n",
       "6220             0.292169           3            2        gcn           1   \n",
       "6221             0.292169           3            2        gcn           1   \n",
       "6222             0.292169          20           19        gcn           1   \n",
       "\n",
       "      Learning Rate  Dropout  Attention Dimension  Attention Bias  \\\n",
       "0             0.005      0.0                   10               1   \n",
       "1             0.005      0.0                   10               1   \n",
       "2             0.005      0.0                   10               1   \n",
       "3             0.005      0.0                   10               1   \n",
       "4             0.005      0.0                   10               1   \n",
       "5             0.005      0.0                   10               2   \n",
       "6             0.010      0.0                   10               2   \n",
       "7             0.005      0.0                   10               2   \n",
       "8             0.005      0.0                   10               2   \n",
       "9             0.010      0.0                   10               2   \n",
       "10            0.005      0.0                   10               2   \n",
       "11            0.005      0.0                   10               2   \n",
       "12            0.005      0.0                   10               2   \n",
       "13            0.010      0.0                   10               2   \n",
       "14            0.010      0.0                   10               1   \n",
       "15            0.005      0.0                   10               2   \n",
       "16            0.010      0.0                   10               1   \n",
       "17            0.005      0.0                   10               2   \n",
       "18            0.005      0.0                   10               2   \n",
       "19            0.010      0.0                   10               2   \n",
       "20            0.005      0.2                   10               3   \n",
       "21            0.010      0.0                   10               1   \n",
       "22            0.005      0.2                   10               2   \n",
       "23            0.010      0.0                   10               3   \n",
       "24            0.010      0.0                   10               1   \n",
       "25            0.005      0.0                   10               2   \n",
       "26            0.005      0.0                   10               3   \n",
       "27            0.005      0.0                   10               2   \n",
       "28            0.010      0.0                   10               1   \n",
       "29            0.005      0.0                   10               2   \n",
       "...             ...      ...                  ...             ...   \n",
       "6193          0.010      0.0                   10               3   \n",
       "6194          0.010      0.0                   10               3   \n",
       "6195          0.005      0.0                   10               3   \n",
       "6196          0.010      0.2                   10               2   \n",
       "6197          0.010      0.2                   10               3   \n",
       "6198          0.010      0.2                   10               1   \n",
       "6199          0.005      0.2                   10               1   \n",
       "6200          0.005      0.0                   10               3   \n",
       "6201          0.010      0.2                   10               3   \n",
       "6202          0.005      0.2                   10               3   \n",
       "6203          0.010      0.2                   10               2   \n",
       "6204          0.010      0.0                   10               2   \n",
       "6205          0.005      0.2                   10               2   \n",
       "6206          0.005      0.0                   10               3   \n",
       "6207          0.005      0.0                   10               3   \n",
       "6208          0.005      0.2                   10               2   \n",
       "6209          0.010      0.2                   10               2   \n",
       "6210          0.005      0.0                   10               2   \n",
       "6211          0.010      0.2                   10               1   \n",
       "6212          0.005      0.0                   10               3   \n",
       "6213          0.005      0.2                   10               1   \n",
       "6214          0.005      0.2                   10               3   \n",
       "6215          0.010      0.0                   10               2   \n",
       "6216          0.010      0.2                   10               1   \n",
       "6217          0.010      0.0                   10               3   \n",
       "6218          0.010      0.2                   10               3   \n",
       "6219          0.010      0.0                   10               3   \n",
       "6220          0.010      0.0                   10               2   \n",
       "6221          0.010      0.0                   10               2   \n",
       "6222          0.010      0.0                   10               2   \n",
       "\n",
       "     Graph Convolution Dimensions Fully Connected Dimensions  \\\n",
       "0                           [20,]                         []   \n",
       "1                           [20,]                         []   \n",
       "2                           [20,]                         []   \n",
       "3                           [20,]                         []   \n",
       "4                           [20,]                         []   \n",
       "5                           [20,]                         []   \n",
       "6                           [10,]                   [20,20,]   \n",
       "7                           [10,]                   [20,20,]   \n",
       "8                        [10,10,]                   [20,20,]   \n",
       "9                           [10,]                   [20,20,]   \n",
       "10                          [10,]                   [20,20,]   \n",
       "11                          [20,]                         []   \n",
       "12                       [10,10,]                   [20,20,]   \n",
       "13                          [10,]                   [20,20,]   \n",
       "14                       [10,10,]                   [20,20,]   \n",
       "15                          [10,]                   [20,20,]   \n",
       "16                       [20,20,]                      [20,]   \n",
       "17                       [20,20,]                      [20,]   \n",
       "18                       [10,10,]                   [20,20,]   \n",
       "19                          [10,]                   [20,20,]   \n",
       "20                       [10,10,]                         []   \n",
       "21                       [10,10,]                   [20,20,]   \n",
       "22                       [10,10,]                      [20,]   \n",
       "23                          [10,]                      [20,]   \n",
       "24                       [20,20,]                      [20,]   \n",
       "25                          [20,]                         []   \n",
       "26                    [20,20,20,]                   [20,20,]   \n",
       "27                       [20,20,]                      [20,]   \n",
       "28                       [10,10,]                         []   \n",
       "29                          [10,]                   [20,20,]   \n",
       "...                           ...                        ...   \n",
       "6193                     [10,10,]                      [20,]   \n",
       "6194                     [20,20,]                         []   \n",
       "6195                     [20,20,]                         []   \n",
       "6196                        [20,]                         []   \n",
       "6197                     [10,10,]                      [20,]   \n",
       "6198                  [10,10,10,]                      [20,]   \n",
       "6199                        [20,]                         []   \n",
       "6200                     [20,20,]                   [20,20,]   \n",
       "6201                        [20,]                      [20,]   \n",
       "6202                     [10,10,]                         []   \n",
       "6203                        [10,]                      [20,]   \n",
       "6204                  [10,10,10,]                      [20,]   \n",
       "6205                     [10,10,]                      [20,]   \n",
       "6206                  [10,10,10,]                      [20,]   \n",
       "6207                     [10,10,]                   [20,20,]   \n",
       "6208                  [10,10,10,]                   [20,20,]   \n",
       "6209                     [20,20,]                         []   \n",
       "6210                     [10,10,]                         []   \n",
       "6211                     [20,20,]                      [20,]   \n",
       "6212                  [10,10,10,]                         []   \n",
       "6213                        [10,]                      [20,]   \n",
       "6214                  [10,10,10,]                      [20,]   \n",
       "6215                        [20,]                   [20,20,]   \n",
       "6216                     [20,20,]                         []   \n",
       "6217                  [20,20,20,]                   [20,20,]   \n",
       "6218                        [20,]                   [20,20,]   \n",
       "6219                     [20,20,]                         []   \n",
       "6220                         [20]                         []   \n",
       "6221                         [20]                         []   \n",
       "6222                         [20]                         []   \n",
       "\n",
       "      Balanced Training  Weight Decay  Early Stopping  \n",
       "0                 False        0.0005             200  \n",
       "1                 False        0.0005             200  \n",
       "2                 False        0.0005             200  \n",
       "3                 False        0.0005             200  \n",
       "4                 False        0.0005             200  \n",
       "5                 False        0.0005             200  \n",
       "6                 False        0.0005             200  \n",
       "7                 False        0.0005             200  \n",
       "8                 False        0.0005             200  \n",
       "9                 False        0.0005             200  \n",
       "10                False        0.0005             200  \n",
       "11                False        0.0005             200  \n",
       "12                False        0.0005             200  \n",
       "13                False        0.0005             200  \n",
       "14                False        0.0005             200  \n",
       "15                False        0.0005             200  \n",
       "16                False        0.0005             200  \n",
       "17                False        0.0005             200  \n",
       "18                False        0.0005             200  \n",
       "19                False        0.0005             200  \n",
       "20                False        0.0005             200  \n",
       "21                False        0.0005             200  \n",
       "22                False        0.0005             200  \n",
       "23                False        0.0005             200  \n",
       "24                False        0.0005             200  \n",
       "25                False        0.0005             200  \n",
       "26                False        0.0005             200  \n",
       "27                False        0.0005             200  \n",
       "28                False        0.0005             200  \n",
       "29                False        0.0005             200  \n",
       "...                 ...           ...             ...  \n",
       "6193              False        0.0005             200  \n",
       "6194              False        0.0005             200  \n",
       "6195              False        0.0005             200  \n",
       "6196              False        0.0005             200  \n",
       "6197              False        0.0005             200  \n",
       "6198              False        0.0005             200  \n",
       "6199              False        0.0005             200  \n",
       "6200              False        0.0005             200  \n",
       "6201              False        0.0005             200  \n",
       "6202              False        0.0005             200  \n",
       "6203              False        0.0005             200  \n",
       "6204              False        0.0005             200  \n",
       "6205              False        0.0005             200  \n",
       "6206              False        0.0005             200  \n",
       "6207              False        0.0005             200  \n",
       "6208              False        0.0005             200  \n",
       "6209              False        0.0005             200  \n",
       "6210              False        0.0005             200  \n",
       "6211              False        0.0005             200  \n",
       "6212              False        0.0005             200  \n",
       "6213              False        0.0005             200  \n",
       "6214              False        0.0005             200  \n",
       "6215              False        0.0005             200  \n",
       "6216              False        0.0005             200  \n",
       "6217              False        0.0005             200  \n",
       "6218              False        0.0005             200  \n",
       "6219              False        0.0005             200  \n",
       "6220               True        0.0005             500  \n",
       "6221               True        0.0005             500  \n",
       "6222               True        0.0005             500  \n",
       "\n",
       "[6223 rows x 16 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"../Results/validation_results.txt\",sep = \"\\t\",index_col=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
